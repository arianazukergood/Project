{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing to break up original dataset file so as to be uploadable onto GitHub (without Git LFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.2.1     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 0.8.3\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 0.8.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.4.0\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(haven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The team wanted to store the raw data on github and not have to use https://git-lfs.github.com\n",
    "\n",
    "# Source for dataset: https://www.fjc.gov/sites/default/files/idb/datasets/cr19_0.sas7bdat\n",
    "\n",
    "# Unfortunately using `read_sas(\"https://www.fjc.gov/sites/default/files/idb/datasets/cr19_0.sas7bdat\")` \n",
    "# i.e. loading straight from the URL doesn't work for some reason\n",
    "\n",
    "cr19_df <- read_sas(\"cr19_0.sas7bdat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "227446"
      ],
      "text/latex": [
       "227446"
      ],
      "text/markdown": [
       "227446"
      ],
      "text/plain": [
       "[1] 227446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(cr19_df) # To decide on reasonable chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source https://stackoverflow.com/a/7060331/6328256\n",
    "chunk <- 40000 # So there will be 6 output files \n",
    "n <- nrow(cr19_df)\n",
    "r <- rep(1:ceiling(n/chunk), each=chunk)[1:n]\n",
    "d <- split(cr19_df, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for csvs\n",
    "dir.create(\"../raw_data_csvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CSV files\n",
    "write_csv(d$`1`, '../raw_data_csvs/cr19_part1.csv', col_names=TRUE)\n",
    "write_csv(d$`2`, '../raw_data_csvs/cr19_part2.csv', col_names=FALSE)\n",
    "write_csv(d$`3`, '../raw_data_csvs/cr19_part3.csv', col_names=FALSE)\n",
    "write_csv(d$`4`, '../raw_data_csvs/cr19_part4.csv', col_names=FALSE)\n",
    "write_csv(d$`5`, '../raw_data_csvs/cr19_part5.csv', col_names=FALSE)\n",
    "write_csv(d$`6`, '../raw_data_csvs/cr19_part6.csv', col_names=FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
